{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kyle/miniconda3/envs/kne/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, LlamaTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'LLaMATokenizer'. \n",
      "The class this function is called from is 'LlamaTokenizer'.\n",
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [02:35<00:00,  1.92s/it]\n"
     ]
    }
   ],
   "source": [
    "# tokenizer = LlamaTokenizer.from_pretrained(\"TheBloke/vicuna-13B-1.1-HF\")\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"TheBloke/vicuna-13B-1.1-HF\", device_map=\"auto\", torch_dtype=torch.float16).eval()\n",
    "\n",
    "tokenizer = LlamaTokenizer.from_pretrained(\"decapoda-research/llama-65b-hf\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"decapoda-research/llama-65b-hf\", device_map=\"auto\", torch_dtype=torch.float16).eval()\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"mosaicml/mpt-7b-instruct\")\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"mosaicml/mpt-7b-instruct\", device_map=\"auto\", torch_dtype=torch.float16, trust_remote_code=True).eval()\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-6.7b\")\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"facebook/opt-6.7b\", device_map=\"auto\", torch_dtype=torch.float16, trust_remote_code=True).eval()\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"OpenAssistant/oasst-sft-4-pythia-12b-epoch-3.5\")\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"OpenAssistant/oasst-sft-4-pythia-12b-epoch-3.5\", device_map=\"auto\", torch_dtype=torch.float16).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset ag_news (/home/kyle/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text': \"Fears for T N pension after talks Unions representing workers at Turner   Newall say they are 'disappointed' after talks with stricken parent firm Federal Mogul.\",\n",
       " 'label': 2}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ag_news = load_dataset(\"ag_news\", split=\"test\")\n",
    "ag_news[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ag_news_frame = ag_news.to_pandas()\n",
    "# labels = sorted(ag_news_frame[\"label\"].unique().tolist())\n",
    "# sample = pd.concat([ag_news_frame[ag_news_frame[\"label\"] == label].sample(4) for label in labels])\n",
    "# sample[\"text\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current_summary = f\"{ag_news[0]['text']}\"\n",
    "\n",
    "# task_prompt = f\"\"\"The assistant is to parpahrase/rewrite a given news summary in the style of a social media tweet. Here are some examples.\n",
    "\n",
    "# Summary: India must recognize international realities: PM Prime Minister Manmohan Singh has responded to the Left #39;s criticism of his congratulatory call to US President George W. Bush by saying India must recognise international realities.\n",
    "# Tweet: ğŸŒ PM Singh urges recognition of international realities! ğŸ‡®ğŸ‡³ğŸŒ Responding to criticism from the Left, he defends his congratulatory call to President Bush, emphasizing the need for India to acknowledge global realities. ğŸ‘¥ğŸ—£ï¸ #InternationalRelations #ManmohanSingh ğŸ“°\n",
    "\n",
    "# Summary: Quincy Carter being released by the Cowboys NEW YORK -- Tim Henman #39;s quarterfinal victory at the US Open was a microcosm of his career - long and brilliant in spurts, with an expected disappointment on the horizon.\n",
    "# Tweet: LOL, Cowboys finally kicked Quincy Carter to the curb! ğŸˆ And hey, Tim Henman at the US Open? Classic Henman: flashy moments followed by an inevitable letdown. ğŸ˜‚ğŸ¾ #SameOldStory\n",
    "\n",
    "# Summary: WellPoint net income increases 28 percent THOUSAND OAKS, Calif. -- WellPoint Health Networks Inc. #39;s third-quarter net income rose 28 percent as the managed-care company saw membership growth in key markets and double-digit revenue growth.\n",
    "# Tweet: ğŸ’¼ğŸ“ˆ WellPoint reports impressive Q3 growth! ğŸ“ŠğŸ’° The managed-care company's net income surged by 28% driven by membership expansion in key markets and substantial revenue growth in double digits. ğŸ‘¥ğŸ’¼ #WellPoint #FinancialResults ğŸ“°\n",
    "\n",
    "# Summary: Microsoft releases fix for SP2-adware clash Microsoft has released a critical update for Windows Service Pack 2, designed to resolve an installation problem with a piece of adware -- but it maintains that the update isn #39;ta patch.\n",
    "# Tweet: Microsoft releases fix for SP2-adware conflict! ğŸ”§ğŸ”’ A critical update for Windows Service Pack 2 is now available, addressing an installation issue related to adware. Microsoft clarifies that the update is not a patch, but rather a resolution for the specific problem. #Microsoft #WindowsSP2 #SoftwareUpdate ğŸ“°\n",
    "\n",
    "# Now rewrite the following news summary in the style of a social media tweet.\n",
    "\n",
    "# Summary: {current_summary}\n",
    "# Tweet:\"\"\"\n",
    "\n",
    "# input_prompt = f\"User: {task_prompt}Assistant:\".replace(\"</s>\", \" \").replace(\"<s>\", \" \")\n",
    "# tokenized_prompt = tokenizer.encode(input_prompt, return_tensors=\"pt\").to(model.device)\n",
    "# with torch.no_grad():\n",
    "#     outputs = model.generate(\n",
    "#         tokenized_prompt,\n",
    "#         max_new_tokens=500,\n",
    "#         length_penalty=0,\n",
    "#         early_stopping=True,\n",
    "#         return_dict_in_generate=True,\n",
    "#         output_scores=True,\n",
    "#     )\n",
    "    \n",
    "# generation = tokenizer.decode(outputs[\"sequences\"][0])\n",
    "# print(generation)\n",
    "\n",
    "# # decode the scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/500 [00:23<3:14:29, 23.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original Summary: Fears for T N pension after talks Unions representing workers at Turner   Newall say they are 'disappointed' after talks with stricken parent firm Federal Mogul.\n",
      "Generated Summary: â€â€â€â€â€â€â€â€â€â€â€â€â€â€â€â€â€â€â€â€â€â€â€â€â€â€â€â€â€â€â€â€â€â€â€â€â€â€â€â€â€â€â€â€â€â€â€â€â€â€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/500 [00:24<3:25:58, 24.77s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m tokenized_prompt \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mencode(input_prompt, return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mto(model\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m     26\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> 27\u001b[0m     outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mgenerate(\n\u001b[1;32m     28\u001b[0m         tokenized_prompt,\n\u001b[1;32m     29\u001b[0m         max_new_tokens\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m,\n\u001b[1;32m     30\u001b[0m         length_penalty\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m     31\u001b[0m         do_sample\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     32\u001b[0m         early_stopping\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     33\u001b[0m         return_dict_in_generate\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     34\u001b[0m         output_scores\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     35\u001b[0m     )\n\u001b[1;32m     37\u001b[0m generation \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mdecode(outputs[\u001b[39m\"\u001b[39m\u001b[39msequences\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m])\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39mTweet:\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m</s>\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mstrip()\n\u001b[1;32m     38\u001b[0m records\u001b[39m.\u001b[39mappend({\n\u001b[1;32m     39\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m: index,\n\u001b[1;32m     40\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39moriginal_summary\u001b[39m\u001b[39m\"\u001b[39m: current_summary,\n\u001b[1;32m     41\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mgenerated_summary\u001b[39m\u001b[39m\"\u001b[39m: generation,\n\u001b[1;32m     42\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m: current_entry[\u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     43\u001b[0m })\n",
      "File \u001b[0;32m~/miniconda3/envs/kne/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/kne/lib/python3.10/site-packages/transformers/generation/utils.py:1437\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, streamer, **kwargs)\u001b[0m\n\u001b[1;32m   1431\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1432\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnum_return_sequences has to be 1, but is \u001b[39m\u001b[39m{\u001b[39;00mgeneration_config\u001b[39m.\u001b[39mnum_return_sequences\u001b[39m}\u001b[39;00m\u001b[39m when doing\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1433\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m greedy search.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1434\u001b[0m         )\n\u001b[1;32m   1436\u001b[0m     \u001b[39m# 11. run greedy search\u001b[39;00m\n\u001b[0;32m-> 1437\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgreedy_search(\n\u001b[1;32m   1438\u001b[0m         input_ids,\n\u001b[1;32m   1439\u001b[0m         logits_processor\u001b[39m=\u001b[39;49mlogits_processor,\n\u001b[1;32m   1440\u001b[0m         stopping_criteria\u001b[39m=\u001b[39;49mstopping_criteria,\n\u001b[1;32m   1441\u001b[0m         pad_token_id\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49mpad_token_id,\n\u001b[1;32m   1442\u001b[0m         eos_token_id\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49meos_token_id,\n\u001b[1;32m   1443\u001b[0m         output_scores\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49moutput_scores,\n\u001b[1;32m   1444\u001b[0m         return_dict_in_generate\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49mreturn_dict_in_generate,\n\u001b[1;32m   1445\u001b[0m         synced_gpus\u001b[39m=\u001b[39;49msynced_gpus,\n\u001b[1;32m   1446\u001b[0m         streamer\u001b[39m=\u001b[39;49mstreamer,\n\u001b[1;32m   1447\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs,\n\u001b[1;32m   1448\u001b[0m     )\n\u001b[1;32m   1450\u001b[0m \u001b[39melif\u001b[39;00m is_contrastive_search_gen_mode:\n\u001b[1;32m   1451\u001b[0m     \u001b[39mif\u001b[39;00m generation_config\u001b[39m.\u001b[39mnum_return_sequences \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/kne/lib/python3.10/site-packages/transformers/generation/utils.py:2305\u001b[0m, in \u001b[0;36mGenerationMixin.greedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2300\u001b[0m     unfinished_sequences \u001b[39m=\u001b[39m unfinished_sequences\u001b[39m.\u001b[39mmul(\n\u001b[1;32m   2301\u001b[0m         next_tokens\u001b[39m.\u001b[39mtile(eos_token_id_tensor\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mne(eos_token_id_tensor\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mprod(dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m   2302\u001b[0m     )\n\u001b[1;32m   2304\u001b[0m \u001b[39m# stop when each sentence is finished, or if we exceed the maximum length\u001b[39;00m\n\u001b[0;32m-> 2305\u001b[0m \u001b[39mif\u001b[39;00m unfinished_sequences\u001b[39m.\u001b[39mmax() \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m stopping_criteria(input_ids, scores):\n\u001b[1;32m   2306\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m synced_gpus:\n\u001b[1;32m   2307\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/kne/lib/python3.10/site-packages/transformers/generation/stopping_criteria.py:111\u001b[0m, in \u001b[0;36mStoppingCriteriaList.__call__\u001b[0;34m(self, input_ids, scores, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mStoppingCriteriaList\u001b[39;00m(\u001b[39mlist\u001b[39m):\n\u001b[0;32m--> 111\u001b[0m     \u001b[39m@add_start_docstrings\u001b[39m(STOPPING_CRITERIA_INPUTS_DOCSTRING)\n\u001b[1;32m    112\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, input_ids: torch\u001b[39m.\u001b[39mLongTensor, scores: torch\u001b[39m.\u001b[39mFloatTensor, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[1;32m    113\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39many\u001b[39m(criteria(input_ids, scores) \u001b[39mfor\u001b[39;00m criteria \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m)\n\u001b[1;32m    115\u001b[0m     \u001b[39m@property\u001b[39m\n\u001b[1;32m    116\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mmax_length\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional[\u001b[39mint\u001b[39m]:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "records = []\n",
    "\n",
    "for index in tqdm(range(500)):\n",
    "    current_entry = ag_news[index]\n",
    "    current_summary = current_entry['text']\n",
    "    task_prompt = f\"\"\"The assistant is to parpahrase/rewrite a given news summary in the style of a social media tweet. Here are some examples.\n",
    "\n",
    "Summary: India must recognize international realities: PM Prime Minister Manmohan Singh has responded to the Left #39;s criticism of his congratulatory call to US President George W. Bush by saying India must recognise international realities.\n",
    "Tweet: ğŸŒ PM Singh urges recognition of international realities! ğŸ‡®ğŸ‡³ğŸŒ Responding to criticism from the Left, he defends his congratulatory call to President Bush, emphasizing the need for India to acknowledge global realities. ğŸ‘¥ğŸ—£ï¸ #InternationalRelations #ManmohanSingh ğŸ“°\n",
    "\n",
    "Summary: WellPoint net income increases 28 percent THOUSAND OAKS, Calif. -- WellPoint Health Networks Inc. #39;s third-quarter net income rose 28 percent as the managed-care company saw membership growth in key markets and double-digit revenue growth.\n",
    "Tweet: WellPoint reports impressive Q3 growth! The managed-care company's net income surged by 28% driven by membership expansion in key markets and substantial revenue growth in double digits. ğŸ‘¥ğŸ’¼ #WellPoint #FinancialResults ğŸ“°\n",
    "\n",
    "Summary: Microsoft releases fix for SP2-adware clash Microsoft has released a critical update for Windows Service Pack 2, designed to resolve an installation problem with a piece of adware -- but it maintains that the update isn #39;ta patch.\n",
    "Tweet: ğŸ’» Microsoft releases fix for SP2-adware conflict! ğŸ”§ğŸ”’ A critical update for Windows Service Pack 2 is now available, addressing an installation issue related to adware. Microsoft clarifies that the update is not a patch, but rather a resolution for the specific problem. #Microsoft #WindowsSP2 #SoftwareUpdate ğŸ“°\n",
    "\n",
    "Summary: Quincy Carter being released by the Cowboys NEW YORK -- Tim Henman #39;s quarterfinal victory at the US Open was a microcosm of his career - long and brilliant in spurts, with an expected disappointment on the horizon.\n",
    "Tweet: LOL, Cowboys finally kicked Quincy Carter to the curb! ğŸˆ And hey, Tim Henman at the US Open? Classic Henman: flashy moments followed by an inevitable letdown. ğŸ˜‚ğŸ¾ #SameOldStory\n",
    "\n",
    "Summary: {current_summary}\n",
    "Tweet: \"\"\"\n",
    "\n",
    "    # input_prompt = f\"User: {task_prompt}Assistant:\".replace(\"</s>\", \" \").replace(\"<s>\", \" \")\n",
    "    input_prompt = task_prompt\n",
    "    tokenized_prompt = tokenizer.encode(input_prompt, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            tokenized_prompt,\n",
    "            max_new_tokens=50,\n",
    "            length_penalty=0,\n",
    "            do_sample=False,\n",
    "            early_stopping=True,\n",
    "            return_dict_in_generate=True,\n",
    "            output_scores=True,\n",
    "        )\n",
    "\n",
    "    generation = tokenizer.decode(outputs[\"sequences\"][0]).split(\"Tweet:\")[-1].split(\"</s>\")[0].strip()\n",
    "    records.append({\n",
    "        \"index\": index,\n",
    "        \"original_summary\": current_summary,\n",
    "        \"generated_summary\": generation,\n",
    "        \"label\": current_entry[\"label\"]\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nOriginal Summary: {current_summary}\")\n",
    "    print(f\"Generated Summary: {generation}\")\n",
    "        \n",
    "    \n",
    "records_frame = pd.DataFrame(records)\n",
    "records_frame.to_csv(\"/home/kyle/repos/Parameter-Free-LM-Editing/datasets/ag_news_twitter/shifted_test_set_small_vicunna.csv\", index=False)\n",
    "records_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MPT-7b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "model = \"tiiuae/falcon-40b-instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for index in tqdm(range(200)):\n",
    "    current_summary = ag_news[index]['text']\n",
    "    task_prompt = f\"\"\"The assistant is to parpahrase/rewrite a given news summary in the style of a social media tweet. Here are some examples.\n",
    "\n",
    "Summary: India must recognize international realities: PM Prime Minister Manmohan Singh has responded to the Left #39;s criticism of his congratulatory call to US President George W. Bush by saying India must recognise international realities.\n",
    "Tweet: ğŸŒ PM Singh urges recognition of international realities! ğŸ‡®ğŸ‡³ğŸŒ Responding to criticism from the Left, he defends his congratulatory call to President Bush, emphasizing the need for India to acknowledge global realities. ğŸ‘¥ğŸ—£ï¸ #InternationalRelations #ManmohanSingh ğŸ“°\n",
    "\n",
    "Summary: Quincy Carter being released by the Cowboys NEW YORK -- Tim Henman #39;s quarterfinal victory at the US Open was a microcosm of his career - long and brilliant in spurts, with an expected disappointment on the horizon.\n",
    "Tweet: LOL, Cowboys finally kicked Quincy Carter to the curb! ğŸˆ And hey, Tim Henman at the US Open? Classic Henman: flashy moments followed by an inevitable letdown. ğŸ˜‚ğŸ¾ #SameOldStory\n",
    "\n",
    "Summary: WellPoint net income increases 28 percent THOUSAND OAKS, Calif. -- WellPoint Health Networks Inc. #39;s third-quarter net income rose 28 percent as the managed-care company saw membership growth in key markets and double-digit revenue growth.\n",
    "Tweet: ğŸ’¼ğŸ“ˆ WellPoint reports impressive Q3 growth! ğŸ“ŠğŸ’° The managed-care company's net income surged by 28% driven by membership expansion in key markets and substantial revenue growth in double digits. ğŸ‘¥ğŸ’¼ #WellPoint #FinancialResults ğŸ“°\n",
    "\n",
    "Summary: Microsoft releases fix for SP2-adware clash Microsoft has released a critical update for Windows Service Pack 2, designed to resolve an installation problem with a piece of adware -- but it maintains that the update isn #39;ta patch.\n",
    "Tweet: Microsoft releases fix for SP2-adware conflict! ğŸ”§ğŸ”’ A critical update for Windows Service Pack 2 is now available, addressing an installation issue related to adware. Microsoft clarifies that the update is not a patch, but rather a resolution for the specific problem. #Microsoft #WindowsSP2 #SoftwareUpdate ğŸ“°\n",
    "\n",
    "Now rewrite the following news summary in the style of a social media tweet.\n",
    "\n",
    "Summary: {current_summary}\n",
    "Tweet:\"\"\"\n",
    "\n",
    "    generation = pipeline(\n",
    "        task_prompt,\n",
    "        max_new_tokens=200,\n",
    "        do_sample=False,\n",
    "        num_return_sequences=1,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "    )[0][\"generated_text\"]\n",
    "\n",
    "    tweet = generation.split(\"Tweet:\")[-1].split(\"\\n\")[0].strip()\n",
    "    print(\"\\nSummary:\", current_summary)\n",
    "    print(f\"Tweet: {tweet}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for index in range(10):\n",
    "#     current_summary = ag_news[index]['text']\n",
    "#     task_prompt = f\"\"\"The assistant is to parpahrase/rewrite a given news summary in the style of a social media tweet. Here are some examples.\n",
    "\n",
    "# Summary: India must recognize international realities: PM Prime Minister Manmohan Singh has responded to the Left #39;s criticism of his congratulatory call to US President George W. Bush by saying India must recognise international realities.\n",
    "# Tweet: ğŸŒ PM Singh urges recognition of international realities! ğŸ‡®ğŸ‡³ğŸŒ Responding to criticism from the Left, he defends his congratulatory call to President Bush, emphasizing the need for India to acknowledge global realities. ğŸ‘¥ğŸ—£ï¸ #InternationalRelations #ManmohanSingh ğŸ“°\n",
    "\n",
    "# Summary: WellPoint net income increases 28 percent THOUSAND OAKS, Calif. -- WellPoint Health Networks Inc. #39;s third-quarter net income rose 28 percent as the managed-care company saw membership growth in key markets and double-digit revenue growth.\n",
    "# Tweet: ğŸ’¼ğŸ“ˆ WellPoint reports impressive Q3 growth! ğŸ“ŠğŸ’° The managed-care company's net income surged by 28% driven by membership expansion in key markets and substantial revenue growth in double digits. ğŸ‘¥ğŸ’¼ #WellPoint #FinancialResults ğŸ“°\n",
    "\n",
    "# Summary: Microsoft releases fix for SP2-adware clash Microsoft has released a critical update for Windows Service Pack 2, designed to resolve an installation problem with a piece of adware -- but it maintains that the update isn #39;ta patch.\n",
    "# Tweet: ğŸ’» Microsoft releases fix for SP2-adware conflict! ğŸ”§ğŸ”’ A critical update for Windows Service Pack 2 is now available, addressing an installation issue related to adware. Microsoft clarifies that the update is not a patch, but rather a resolution for the specific problem. #Microsoft #WindowsSP2 #SoftwareUpdate ğŸ“°\n",
    "\n",
    "# Summary: Quincy Carter being released by the Cowboys NEW YORK -- Tim Henman #39;s quarterfinal victory at the US Open was a microcosm of his career - long and brilliant in spurts, with an expected disappointment on the horizon.\n",
    "# Tweet: LOL, Cowboys finally kicked Quincy Carter to the curb! ğŸˆ And hey, Tim Henman at the US Open? Classic Henman: flashy moments followed by an inevitable letdown. ğŸ˜‚ğŸ¾ #SameOldStory\n",
    "\n",
    "# Now rewrite the following news summary in the style of a social media tweet.\n",
    "\n",
    "# Summary: {current_summary}\n",
    "# Tweet: \"\"\"\n",
    "\n",
    "#     input_prompt = f\"<|prompter|>{task_prompt}<|endoftext|><|assistant|>\".replace(\"</s>\", \" \").replace(\"<s>\", \" \")\n",
    "#     tokenized_prompt = tokenizer.encode(task_prompt, return_tensors=\"pt\").to(model.device)\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model.generate(\n",
    "#             tokenized_prompt,\n",
    "#             max_new_tokens=500,\n",
    "#             length_penalty=0,\n",
    "#             early_stopping=True,\n",
    "#             return_dict_in_generate=True,\n",
    "#             output_scores=True,\n",
    "#         )\n",
    "\n",
    "#     generation = tokenizer.decode(outputs[\"sequences\"][0]).split(\"Tweet: \")[-1].split(\"</s>\")[0].strip()\n",
    "#     print(generation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
